%!TEX root = ../Thesis.tex


% % TODO: Anpassung wenn Grundlagen fertig

\chapter{Rekonstruktion von Fahrzeugtrajektorien aus Luftaufnahmen}
\label{sec:position_extraction}

% Beschreibung des kompletten Vorgangs bis Bewegungsbahnen der Autos vorliegen
% Tracking --> World-Matching --> initiale Glättung
% Resultat beschreiben: Koordinaten der Fahrzeuge in World-Koord.-System --> Distanzen in Metern (ermöglicht "Plausibilitätskontrollen")
% Verwendung von Bounding-Boxes (Mittelpunkt bzw. Front-Punkt identifiziert Fahrzeugposition)
% --> evlt. Problem bei Aufnahmen mit niedrigem Kamera-Winkel

% Die in dieser Arbeit verwendeten Fahrzeugtrajektorien stammen aus der Anwendung ``Tracker-Application''
% des MEC-View Teilprojektes \textit{Luftbeobachtung}. Nachfolgend wird beschrieben, wie diese aus den Videoaufnahmen
% rekonstruiert werden.

% allgemein: Es existieren unterschiedliche Ansätze zur Identifikation und Tracking von Fahrzeugen in Aufnahmen
% Einerseits: Supervised Tracking (alter Ansatz)
% Oder: Hintergrund Subtraktionsverfahren (???) (Eher nicht)
% Oder: Unsupervised Tracking. Object Detection API Tensorflow. So in TrackerApplication
%     Erkennung von Fahrzeugen in jedem einzelnen Frame des Video
%     Erstellen von Bounding Boxes --> Daraus Positionen
% Positionen in Bildkoordinaten
% Umwandlung in Weltkoordinaten (Weltkoordinaten System, Kameramodell etc.. siehe Arbeit Stefan)
% Endergebnis: Fahrzeugpositionen in Weltkoordinatensystem mit Einheit Meter

In diesem Kapitel wird erläutert, wie auf Luftaufnahmen Trajektorien von Fahrzeugen rekonstruiert werden können.
Eine solche Rekonstruktion wird zwar im Rahmen dieser Arbeit nicht entwickelt, allerdings ist es wichtig ein Grundverständnis
der benötigten Methoden und Schritte zu besitzen, um die Trajektoriedaten und die darin enthaltenen Defekte
interpretieren zu können.
Es wird nachfolgend beschrieben, wie bewegte Objekte in Videoaufnahmen erkannt und verfolgt
werden können um anschließend deren Positionen in einem Weltkoordinatensystem zu bestimmen. Am Ende des Kapitels
werden einige Schwierigkeiten, welche bei der Rekonstruktion der Trajektorien auftreten können aufgezeigt.

\section{Erkennung und Verfolgung von Objekten in Videoaufnahmen}

Es existieren diverse Ansätze, welche zur Erkennung und Verfolgung von Objekten in Videoaufnahmen eingesetzt werden können.
Nachfolgend werden zwei unterschiedliche Vorgehens-Arten vorgestellt.

\subsection{Supervised-Tracking}

Bei einem Verfahren aus der Kategorie \textit{Supervised-Tracking} wird ein initial manuell ausgewählter Bildbereich
automatisch mit Hilfe eines erlernten Klassifikators verfolgt. Der Klassifikator muss hierbei zwischen
Fahrzeugen und der Umgebung unterscheiden können.
Der hier beispielhaft vorgestellte Supervised-Tracking Ansatz beruht auf der Arbeit von \cite[]{Grabner}.
Sein grundlegendes Vorgehen ist in Abbildung \ref{fig:grund_tracking} dargestellt und kann wie folgt
beschrieben werden:

\begin{itemize}
    \item[a)] Ein zu verfolgendes Objekt befindet sich zum Zeitpunkt $t$ an bekannter Position $p_1$
    \item[b)] Zum Zeitpunkt $t+1$: Anwendung des Klassifikators auf Positionen um $p_1$
    \item[c)] Erstellen einer \textit{Confidence Map}, welche die Wahrscheinlichkeit darstellt,
                das verfolgte Objekt gefunden zu haben
    \item[d)] Updaten des Trackers auf Position des Maxima der \textit{Confidence Map}
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{resources/img/grundlagen/TrajectoryReconstruction/tracking}
    \caption[Übersicht Tracking mit Klassifikator]{Übersicht Tracking mit Klassifikator \cite[]{Grabner}}
    \label{fig:grund_tracking}
\end{figure}

Zum Erlernen eines stabilen Klassifikators, wird in \cite[]{Grabner} ein On-line AdaBoost Algorithmus eingesetzt,
welcher mehrere \textit{schwache} Klassifikatoren zu einem \textit{starken} Klassifikator kombiniert.
Schwache Klassifikatoren müssen nur eine Erkennungsrate von mehr als 50\% besitzen und somit
wenig besser als zufallsbedingtes Auswählen sein.
Starke Klassifikatoren entstehen durch die Kombination von mehreren schwachen Klassifikatoren.
Die Auswahl von schwachen Klassifikatoren erfolgt über sogenante Selektoren, welche aus einer Menge
immer jenen wählen, welcher die geringste Fehlerrate bei der Erkennung
der Trainings-Objekte besitzen. Der Klassifikator mit der schlechtesten Erkennungsrate wird in jeder
Trainingsiteration ersetzt, um das Training zu verbessern.
Großer Vorteil der On-line AdaBoost Methode ist, dass sie es ermöglicht, starke Klassifikatoren während des
eigentlichen Trackingvorganges zu erlernen. Nach jedem Trackingschritt wird das erfolgreich erkannte
Objekt in Trainingssätze zerlegt, auf welche die Klassifikatoren angewandt werden um ihre Performance zu evaluieren.
So wird in jedem Schritt die Menge der schwachen Klassifikatoren und der Selektoren aktualisiert. Die Wahl
von effizient berechenbaren schwachen Klassifikatoren macht dies möglich.

Die in \cite[]{Grabner} verwendeten Klassifikatoren sind binär, das heißt,
sie teilen Objekte in die zwei Klassen \textit{erkannt} und \textit{nicht erkannt} auf.
Konkret werden Haar-ähnliche Bildmerkmale nach \cite[]{Viola} als schwache Klassifikatoren verwendet.
Diese sind ein Mittel zur Identifikation von Kontrastunterschieden in Bildern, welche sich sehr gut
zur Erkennung von Kanten und Linien eigenen. Ein Beispiel der Haar-ähnlichen Merkmale und ihres Einsatzes
bei der Gesichtserkennung ist in Abbildung \ref{fig:grund_hair_like} dargestellt.

Diese Merkmale werden als schwache Klassifikatoren mit zufälliger Skalierung, Größe und Position
auf dem Bild platziert. Sie suchen in dieser Region anschließend nach den von dem Muster definierten
Konturunterschieden. Eine Bereich gilt als erkannt, wenn der Betrag der Differenz der Pixelsumme des weißen und
schwarzen Bereiches des Musters unter einem festgelegten Grenzwert liegt.

\begin{figure}[H]
    \centering
    \subfloat[]{{
        \includegraphics[width=0.4\linewidth]{resources/img/grundlagen/TrajectoryReconstruction/hair_like_features}
    }}
    \qquad
    \subfloat[]{{
        \includegraphics[width=0.35\linewidth]{resources/img/grundlagen/TrajectoryReconstruction/hair_like_features_2}
    }}
    \caption[Haar-ähnliche Merkmale a), Beispiele für erkannte Regionen in einem Gesicht b)]{Haar-ähnliche Merkmale a), Beispiele für erkannte Regionen in einem Gesicht b) \cite[]{DivyanshDwivedi2018}}
    \label{fig:grund_hair_like}
\end{figure}

Haar-ähnliche Bildmerkmale eignen sich auch gut zur Erkennung von Fahrzeugen in Bildern, da auch diese anhand klarer
Kanten identifiziert werden können.
Gelingt die Verfolgung eines Objektes in einer Videoaufnahme, so existiert nach dem Tracking idealerweise
für jedes Video-Frame, in welchem das Objekt zu sehen ist, eine Position in Pixel-Koordinaten.
Der große Nachteil des Supervised-Trackings ist, das die Positionen verfolgter Objekte initial
manuell definiert werden müssen. Wenn in einer Aufnahme viele Objekte verfolgt werden sollen, dann ist
diese initiale Positionsbestimmung sehr aufwendig.

In nachfolgendem Abschnitt wird daher eine weitere Klasse von Tracking-Verfahren beschrieben,
welche die Positionen von Objekten voll-automatisch in Aufnahmen ermitteln können.

\subsection{Unsupervised-Tracking}

Von \textit{Unsupervised-Tracking} wird gesprochen, wenn zur Identifikation und Verfolgung eines Objektes
in einem Video keine initiale \textit{Region of Interest} (\acrshort*{roi}) definiert werden muss,
welche die Startposition des Objektes festlegt. Die Erkennung und Verfolgung funktioniert daher komplett automatisch.
Es existieren verschieden Verfahren, welche in die Kategorie des Unsupervised-Tracking fallen. Auch in
der \textit{Vehicle-Tracker} Anwendung, auf welcher diese Arbeit aufbaut, wird Unsupervised-Tracking eingesetzt,
um die Positionen der Fahrzeuge in den Videoaufnahmen zu bestimmen. Das hier eingesetzte Verfahren wird nachfolgend
beispielhaft in groben Zügen erläutert.

Während im Fall des oben beschriebenen Supervised-Tracking-Ansatzes
Objekte grundsätzlich einmal händisch detektiert und anschließend verfolgt werden, werden im Fall des
Ansatzes, welcher in der \textit{Vehicle-Tracker} Applikation zur Anwendung kommt, die Positionen der Fahrzeuge
in jedem Video-Frame neu bestimmt. Die Positionsinformationen eines Fahrzeugs werden anschließend zu
zusammenhängenden Trajektorien zusammengefasst. Erkannt werden
die Fahrzeuge mithilfe der \textit{Object-Detection-API} von Tensorflow\footnote{Tensorflow - \url{https://www.tensorflow.org/}}.

Das quelloffene Machine-Learning Framework Tensorflow bietet in seiner \textit{Object-Detection-API}
verschiedene Netzwerk-Architekturen und vortrainierte Modelle an, welche zur Erkennung und Klassifizierung
von Objekten eingesetzt werden können \cite[]{Huang2018}. Die hierzu angebotenen neuronale Netze sind Weiterentwicklungen
von \textit{Convolutional Neural Networks} (\acrshort*{cnn}), welche sich gut zur maschinellen Verarbeitung
von Bilddaten eignen.

In Abbildung \ref{fig:grund_structure_cnn} ist der Aufbau eines CNNs inklusive eines \textit{Fully-Connected Layers} dargestellt.
Ein genaues Verständnis der Funktionsweise eines solchen Netzwerks ist im Fall dieser Arbeit nicht notwendig.
Grundlegend besteht es allerdings aus zwei Komponenten: Der erste Teil des Netzwerkes ist für
das \textit{Feature Learning} verantwortlich, während der zweite Teil der Klassifizierung dient.
In der Phase des \textit{Feature Learnings} extrahiert das Netzwerk aus einem Bild Merkmale, mittels
welcher die zu erkennenden Objekte beschrieben werden können. Anhand der extrahierten Merkmale können
ROIs bestimmt werden. Um welches Objekt es sich in einer speziellen ROI handelt, wird anschließend anhand
des \textit{Fully-Connected-Layers} bestimmt.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\linewidth]{resources/img/grundlagen/TrajectoryReconstruction/cnn_structure}
    \caption[Aufbau eines CNNs]{Aufbau eines CNNs \cite[]{PatelShyamal2017}}
    \label{fig:grund_structure_cnn}
\end{figure}

Im Fall der Tensorflow Object Detection API werden die Positionen der erkannten Objekte über sogenannte
\textit{Bounding-Boxes} beschrieben. Diese leiten sich aus den ROIs ab, welche vom CNN ermittelt werden.

Um aus den Positionsinformationen, welche aus den einzelnen Video-Frames extrahiert wurden, zusammenhängende
Fahrzeugtrajektorien erstellen zu können, müssen diese eindeutig einzelnen Fahrzeugen zugeordnet werden.

% TODO: Finish after talk with Stefan

\section{Positionsbestimmung in Videoaufnahmen}

Nachdem die Positionen der Fahrzeugen in 2D-Bildkoordinaten bestimmt wurden, müssen diese in 3D-Weltkoordinaten
umgewandelt werden, um die genauen Fahrzeugpositionen auf der Straße zu erhalten. Dank der Verwendung eines
statitionären Weltkoordinatensystems mit Einheit Meter, lassen sich zudem reale Entfernungen
in der Aufnahme ermitteln, was beispielsweise für die Bestimmung der Fahrzeuggeschwindigkeiten sehr wichtig ist.

Um eine Bildkoordinate in eine Weltkoordinate überführen zu können, müssen vorher verschiedene Kameraeigenschaften
ermittelt werden. Hierzu ist es wichtig ein grundlegendes Verständnis von der Funktionsweise einer Kamera zu besitzen.
Anhand eines Lochkameramodells lässt sich die Funtkionsweise der Bildprojektion einer Kamera herleiten.
Ein solches Modell ist in Abbildung \ref{fig:grund_pinhole_model} dargestellt.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.55\linewidth]{resources/img/grundlagen/TrajectoryReconstruction/pinhole_camera_model}
    \caption[Lochkameramodell]{Lochkameramodell \cite[]{DevTeamOpenCV2018}}
    \label{fig:grund_pinhole_model}
\end{figure}

In einer Lochkamera fällt Licht durch eine kleine Öffnung auf eine Projektionsfläche. Es werden keine Linsen
zur Bündelung des Lichtes eingestzt. Für die Projektion eines Punktes $P$ auf diese Fläche müssen vier
Bezugsysteme berücksichtigt werden:

\begin{enumerate}
    \item Das \textbf{Weltkoordinatensystem} ist ein statitionäres Bezugsystem, dessen Ursprung sich an einem beliebigen Punkt
            im aufgenommenen Raum befindet. Über dieses System werden Punkte $P = (X, Y, Z)$ definiert.
    \item Das \textbf{Kamerakoordinatensystem} hat seinen Ursprung im Punkt $F_c$, der Öffnung des Kamerasystems.
            Es definiert Punkte $P = (x_c,\ y_c,\ z_c)$ relativ zur Kamera.
    \item Das \textbf{Projektionskoordinatensystem} hat seinen Ursprung im Punkt $C = (c_x,\ c_y)$ der Projektionsfläche.
            Über es werden zweidimensione Punkte $P' = (x_p, y_p)$ definiert.
    \item Der Ursprung des \textbf{Bildschirmkoordinatensystem} ist die linke obere Ecke der Projektionsfläche.
            Über es werden Punkte $P' = (u,\ v)$ in der Einheit Pixel definiert.
\end{enumerate}

Unter Berücksichtigung dieser Bezugssysteme können die sogenannten ``intrisischen'' und ``extrinsischen Kameraparameter''
bestimmt werden.

\subsubsection{Intrinsische Kamera- und Verzeichnungsparameter}

Die intrinsischen Kamera- und Verzeichnungsparameter sind abhängig von der Bauart der Kamera und gelten
daher für alle Aufnahmen, welche mit der selben Hardware-Konfiguration getätigt werden.
Die Parameter $c_x$ und $c_y$, welche die Bildmitte festlegen und die
horizontale und vertikale Brennweite $f_x$ und $f_y$ definieren die intrinsischen Kameraparameter.
Mit ihrer Hilfe lässt sich eine Kameramatrix der Form

\begin{ceqn}
\begin{align}
A =
 \begin{bmatrix}
  f_x & 0 & c_x \\
  0 & f_y & c_y \\
  0 & 0 & 1
 \end{bmatrix}
\end{align}
\end{ceqn}

bilden.
Die Verzeichungsparameter sind abhängig von den Linsen, welche in einer Kamera verwendet werden. Diese sorgen
für radiale und tangentiale Verzerrungen des Bildes. Die Parameter $k_1$, $k_2$ und $k_3$ definieren die
radiale Verzeichnung und $p_1$ und $p_2$ die tangentiale Verzeichnung. \cite[]{Meissner2007}

Die intrinsischen Kamera- und Verzeichungsparameter können durch ein Kalibrierungsverfahren bestimmt werden.
Computervision-Bibliotheken wie OpenCV bieten hierfür Hilfsfunktionen an \cite[]{DevTeamOpenCV2018}.

\subsubsection{Extrinsische Kameraparameter}

Die extrinsischen Kameraparameter definieren, wie ein Punkt des 3D-Weltkoordinatensystems in einen 3D-Punkt
des Kamerakoordinatensystems überführt wird.
Die Transformation ist in Gleichung \ref{eq_point_transformation} beschrieben:

\begin{ceqn}
\begin{align}
\label{eq_point_transformation}
    P_c = R P_w + t
\end{align}
\end{ceqn}

$R$ und $t$ sind die extrinsischen Kameraparameter. $R$ ist die sogenannte Rotationsmatrix, welche
die Drehung der Kamera um die X, Y und Z-Achse enthält. $t$ ist der Translationsvektor, welcher angibt
wieweit der Ursprung des Weltkoordinatensystems von der Kamera entfernt ist.

Die extrinsischen Parameter einer Aufnahme lassen sich mithilfe der intrinsischen Kamera- und Verzeichnungsparameter
und mindestens sechs Weltkoordinaten, welche Bildschirmkoordinaten zugeordnet werden können, bestimmen. Bibliotheken
wie OpenCV bieten auch hierfür Funktionen an.

\subsubsection{Transformation von Bildschirmpositionen in Weltkoordinaten}

Die Trasformation einer Weltkoordinate in eine Bildschirmposition ist, ohne Berücksichtigung der Verzeichnung,
gegeben durch die Formel \ref{eq_point_transformation2}. $s$ ist hier ein konstanter Skalierungsfaktor.

\begin{ceqn}
\begin{align}
\label{eq_point_transformation2}
    s\ \big[u\ v\ 1\big]^T = A \big[R\ t\big]\ P_w
\end{align}
\end{ceqn}

Da bei der Projektion vom Weltkoordinatensystem ins Bildschirmkoordinatensystem eine Dimensionsinformation
verloren geht, muss bei der Rücktrasformation diese extra bestimmt oder geschätzt werden. Liegt ein Punkt
auf der Ebene, welche von der X- und Y-Achse des Weltkoordinatensystems beschrieben wird, kann für dessen
Höhe $z = 0$ verwendet werden.
Die Position eines Punktes $P_w$ kann so mithilfe des folgenden Gleichungssystems bestimmt werden:

\begin{ceqn}
\begin{align}
\label{eq_point_transformation3}
    \big[x_w\ y_w\ 0\big]^T = R^{-1}\Big(sA^{-1} \big[u\ v\ 1\big]^T - t\Big)
\end{align}
\end{ceqn}

In der Anwendung \textit{Vehicle-Tracker} werden auf diese Weise alle Bildschirmkoordinaten der Trajektorien
in Weltkoordinaten umgewandet.

\section{Herausforderungen bei der Rekonstruktion von Fahrzeugtrajektorien}

\chapter{Clusteranalyse}
\label{sec:tra_clustering}


Die Clusteranalyse (kurz Clustering) ist ein wichtiges Werkzeug zur Auswertung von Daten unterschiedlichster
Art. Sie stellt dabei kein konkretes Vorgehen oder einen Algorithmus dar, sondern beschreibt ein
allgemeines Problem, welches auf unterschiedlichste Weise gelöst werden kann. Eine Definition ist nachfolgend
gegeben:

\begin{mydef}%[Clusteranalyse]
    Die Clusteranalyse ist ein Verfahren um Datenobjekte aufgrund ihrer Eigenschaften und Beziehungen
    untereinander so zu gruppieren, dass sich die Objekte einer Gruppe möglichst stark ähneln und sich
    von den Objekten anderer Gruppen möglichst stark unterscheiden. Die auf diese Art entstehenden
    Objektgruppen werden \textit{Cluster} genannt. Foo
\end{mydef}

Je höher die \textit{Homogenität} in einem Cluster
und die \textit{Differenz} zwischen den Clustern, desto besser ist die gewählte Clustering Methode.
Der Einsatz einer Clusteranalyse ist in vielen Anwendungsgebieten und in den unterschiedlichsten wissenschaftlichen
Disziplinen sehr beliebt, um ein Verständnis für Daten zu erhalten, beziehungsweise diese, nach einer Gruppierung,
sinnvoll weiter verarbeiten zu können.
So kommt die Clusteranalyse unter anderem in den Feldern des maschinellen Lernens, der Mustererkennung, Bildanalyse,
der Biologie (Taxonomie) oder im Bereich Data Mining zum Einsatz. \cite[]{tan2007introduction}

Die Clusteranalyse hat viel mit dem Problem der Klassifizierung von Daten gemein, insofern sie Datenobjekten
Label zuordnet. Im Gegensatz zu \textit{überwachten} Klassifizierungsansätzen, wie dem heute populären überwachten
Lernen, leiten Cluster-Algorithmen die Label allerdings alleine aus den vorhandenen Daten ab.
Es kommen keine Vergleichsobjekte mit bekannten, händisch vergebenen Labeln zum Einsatz.
Aus diesem Grund wird die Clusteranalyse auch häufig als \textit{unüberwachte Klassifizierung} bezeichnet. \cite[]{tan2007introduction}

Das Konzept eines \textit{Clusters} ist nicht genau definiert. Es existieren daher viele unterschiedliche Konzepte
und Algorithmen, welche sich jeweils für andere Anwendungsfälle eignen und verschiedene Eigenschaften
besitzen. Somit ist das Clustering kein selbsttätiger Prozess, welcher sich in
einheitlicher Weise auf unterschiedliche Probleme anwenden lässt. Jedes Problem erfordert die individuelle und sorgfältige
Auswahl eines passenden Algorithmus, eines Distanzmaßes und der richtigen Parameter. Die Bestimmung dieser geschieht
iterativ und nicht selten nach dem Prinzip des \textit{Trial and Error}. In Abbildung \ref{fig:grund_clustering_example}
ist beispielhaft ein Datensatz (links) mit -- für den Menschen intuitiv ersichtlich -- 7 unterschiedlichen Clustern (rechts)
dargestellt. Nach \cite[]{Jain2010} kann allerdings kein existierender Clustering Algorithmus diese alle erkennen.
\cite[]{Jain1999, tan2007introduction}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{resources/img/grundlagen/clustering_example}
    \caption[Rohdaten (links) und erwünschtes Clustering-Ergebnis (rechts)]{Rohdaten (links) und erwünschtes Clustering-Ergebnis (rechts) \cite[]{Jain2010}}
    \label{fig:grund_clustering_example}
\end{figure}

Aufgrund der Einschränkungen, welche alle Cluster-Algorithmen besitzen, muss der Analyst sich vor deren Anwendung intensiv
mit den zu verarbeitenden Daten beschäftigen. Er muss ein Verständnis dafür besitzen, welche Struktur die Daten
haben, beziehungsweise annehmen können, und nach welchen Mustern zu suchen ist.
Besonders wichtiger ist zudem auch die Auswahl der richtigen, also relevanten, Datenmerkmale (\textit{``Feature Selection''})
und die Wahl deren Repräsentation (\textit{``Feature Transformation''}).
Die Selektion und gegebenenfalls Transformation der Daten muss in einem
Vorverarbeitungsschritt geschehen, dessen Qualität einen maßgeblichen Einfluss auf das finale Clustering-Ergebnis hat.
Basierend auf vorangegangener Beschreibung und \cite[]{Jain1999}, lässt sich der grundlegende Ablauf einer Clusteranalyse wie folgt darstellen: \\

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{resources/img/grundlagen/clustering_flow}
    \caption{Ablauf einer Clusteranalyse}
    \label{fig:grund_clustering_workflow}
\end{figure}

\cite[]{Jain2010} nennt einige weitere Herausforderungen, welcher man sich bei der Clusteranalyse bewusst sein muss:

\begin{enumerate}
    \item Daten können Ausreißer enthalten. Wie sollen diese behandelt werden?
    \item Die Anzahl der Zielcluster ist üblicherweise nicht bekannt. Wie kann sie im voraus bestimmt werden, wenn die Analyse es erfordert?
    \item Wie können gefundenen Cluster validiert werden?
\end{enumerate}

\section{Cluster-Sets und Cluster}

Cluster-Sets, das heißt die Gesamtheit aller durch eine Analyse gefundenen Cluster, und einzelnen Cluster selbst,
können in verschiedene Kategorien unterteilt werden, beziehungsweise unterschiedliche Eigenschaften besitzen.
Nachfolgend sind die wichtigsten basierend auf \cite[]{tan2007introduction} und \cite[]{Jain1999,Jain2010} aufgeführt.

\subsection{Eigenschaften von Cluster-Sets}

Bei Cluster-Sets kann grundsätzlich zwischen nachfolgenden Eigenschaften unterschieden werden.

\paragraph{Hierarchisch vs. Partitioniert}
Von \textit{hierarchischen} Cluster-Sets wird gesprochen, wenn die einzelnen Cluster verschachtelt sind und dabei eine
Baum-Struktur bilden. Cluster sind hingegen \textit{partitioniert}, wenn keine Überlagerungen zwischen ihnen existiert.

\paragraph{Exklusiv vs. Überlappend vs. Fuzzy}
\textit{Exklusive} Cluster-Sets liegen vor, wenn jedem Datenwert ein oder kein Zielcluster zugeordnet wird.
Im Gegensatz hierzu können bei \textit{überlappenden} Cluster-Sets Objekte einer oder mehrerer Gruppen angehören.
Bei dem sogenannten \textit{Fuzzy} oder \textit{Soft} Cluster-Sets, gehört ein Datenobjekt einem Cluster
mit einer bestimmten Wahrscheinlichkeit oder Gewicht an. Algorithmen, welche Daten eine
Wahrscheinlichkeit für die Zugehörigkeit zu einem Cluster zuweisen, werden \textit{probabilistische}
Cluster-Algorithmen genannt.

\paragraph{Komplett vs. Partielle}
Von \textit{kompletten} Cluster-Sets wird gesprochen, wenn jedes Element der Eingangsdaten einem Cluster zugeordnet wird.
Bei \textit{partiellen} Sets ist dies nicht der Fall. Hier kann ein bestimmter Anteil an Datenwerten als Ausreißer markiert
werden, welche keine Gruppe besitzen.

% TODO: evtl. Bild einfügen

\subsection{Eigenschaften von Clustern}

Da, wie oben erwähnt, nicht klar definiert ist, was ein Cluster ausmacht, können auch diese unterschiedliche Eigenschaften
besitzen. Die wichtigsten Cluster-Arten sind nachfolgend erläutert.

\paragraph{Klar separierte Cluster}
Unter \textit{klar separiereten} Clustern versteht man solche, in welchen jedes Datenelement einen geringeren
Abstand zu allen anderen Elementen des Clusters hat, als zu Elementen außerhalb des Clusters.
Dargestellt ist dies in Abbildung \ref{fig:basic_cluster_style} a). Diese idealistische Definition eines
Clusters ist nur dann erfüllt, wenn die in den Daten enthaltenen Cluster einen großen Abstand voneinander haben.
Dies ist in der Realität allerdings selten der Fall.

\paragraph{Prototyp basierte Cluster}
Von einem \textit{Prototyp basierten} Cluster wird gesprochen, wenn alle Elemente einer Gruppe einen
geringeren Abstand zu einem Prototyp oder Referenzwert des Clusters besitzen, als zu denen anderer Gruppierungen (siehe Abb. \ref{fig:basic_cluster_style} b)).
Ein solcher Prototyp ist üblicherweise der Mittelwert der Datenelemente eines Clusters (\textit{Centroid}).

\paragraph{Graphen basierte Cluster}
Die Definition eines \textit{Graphen basierten} Clusters kann immer dann verwendet werden, wenn Daten
als vernetzter Graph dargestellt werden. In einem solchen sind die Elemente Knoten und die Kanten
repräsentieren Beziehungen zwischen ihnen. Ein Cluster in einem solchen Graphen ist definiert als Menge von
Knoten, welche untereinander verbunden sind, jedoch keine Verbindungen zu Elementen außerhalb des Clusters haben.
Dargestellt ist dies in Abbildung \ref{fig:basic_cluster_style} c).

\paragraph{Dichte basierte Cluster}
\textit{Dichte basierte} Cluster sind definiert als Regionen mit einer hohen Dichte an Objekten, welche von
Regionen umgeben sind, welche eine geringe Objektdichte besitzen (siehe Abb. \ref{fig:basic_cluster_style} d)). Elemente, welche in einer solchen Region
mit geringen Dichte liegen, werden als Ausreißer interpretiert. Dichte Bereiche werden üblicherweise
gefunden, indem die Nachbarschaften von Elementen untersucht werden.

\paragraph{Konzeptionelle Cluster}
Eine sehr allgemeine Definition eines Clusters ist die der \textit{konzeptionellen} Gruppen. Hiermit ist
gemeint, dass die Elemente eines Clusters einige gemeinsame Eigenschaften besitzen. Dies schließt die oben genannten
Cluster-Arten mit ein, lässt sich allerdings beliebig erweitern. So sind beispielsweise in Abbildung \ref{fig:basic_cluster_style} e)
konzeptionelle Cluster dargestellt, die die Form zweier Kreise und eines Rechtecks haben. Um solche Muster
erkennen zu können, benötigt ein Algorithmus ein spezielles ``Verständnis'' eines Clusters.

\begin{figure}[H]
    \centering
    \subfloat[Klar separierte Cluster]{{
        \includegraphics[align=c, width=0.3\linewidth]{resources/img/grundlagen/cluster/Cluster01}
    }}
    \qquad
    \qquad
    \subfloat[Centroid-basierte Cluster]{{
        \includegraphics[align=c, width=0.3\linewidth]{resources/img/grundlagen/cluster/Cluster02}
    }}
    \hfill
    \subfloat[Graphen-basierte Cluster]{{
        \includegraphics[align=c, width=0.3\linewidth]{resources/img/grundlagen/cluster/Cluster03}
    }}
    \qquad
    \qquad
    \subfloat[Dichte-basierte Cluster]{{
        \includegraphics[align=c, width=0.3\linewidth]{resources/img/grundlagen/cluster/Cluster04}
    }}
    \hfill
    \subfloat[Konzeptionelle Cluster]{{
        \includegraphics[align=c, width=0.6\linewidth]{resources/img/grundlagen/cluster/Cluster05}
    }}
    \caption[Visualisierung verschiedener Clusterarten]{Visualisierung verschiedener Clusterarten (basierend auf \cite[]{tan2007introduction})}
    \label{fig:basic_cluster_style}
\end{figure}

\section{Cluster-Algorithmen}
\label{sec:cluster_algos}

Um mit den oben beschriebenen unterschiedlichen Cluster-Sets und Cluster Definitionen umgehen zu können,
existieren verschiedene Clustering-Modelle.
Einige wichtige Clustering-Ansätze sind die Vernetzungs-Modelle, Centroid-basierte-Modelle, Verteilungs-Modelle
oder Dichte-Modelle. Für jedes dieser Modelle existieren unterschiedliche Algorithmen. Im Folgenden werden
diese Modelle und jeweils exemplarisch ein Algorithmus, der diese vertritt, vorgestellt.

\subsection{Vernetzungs-Modelle}
\label{sec:grund_vernetzungs_clustering}

Vernetzungs-Modelle werden auch häufig \textit{hierarchische Cluster-Modelle} genannt. Sie beruhen auf
der Annahme, dass Elemente, welche nahe beieinander liegen, eine höhere Gemeinsamkeit besitzen als solche,
welche weiter voneinander entfernt sind. Zur Bestimmung der Nähe zwischen Elementen benötigen Vernetzungs-Modelle,
wie auch andere Cluster-Modelle, eine
Definition von Distanz. Diese legt ein sogenanntes \textit{Distanzmaß} fest. Zusätzlich ist ein \textit{Link-Kriterium} notwendig,
welches bestimmt, wie genau die Entfernung zwischen zwei Clustern ermittelt wird. Übliche Link-Kriterien
sind \textit{Minimum-Linkage}, welches die minimale Distanz zwischen den Objekten der Cluster als Distanz verwendet,
oder \textit{Maximum-Linkage} beziehungsweise \textit{Average-Linkage}. \cite[]{Jain1999, GeorgeSeif2018}

% TODO: Evtl Bild Linkage einfügen

Grundsätzlich teilen sich hierarchische Cluster-Algorithmen in zwei Gruppen auf:
\textit{Agglomerative} (Bottom-Up) und \textit{Divisive} (Top-Down) Algorithmen.
Agglomerative Ansätze weisen zu Beginn des Cluster-Vorgangs jedem Datenelement eine eigene Gruppe zu und vereinigen
diese anschließend.
Bei divisiven Ansätzen werden hingegen zu Beginn alle Elemente in einem Cluster zusammengefasst und
diese in den nachfolgenden Schritten geteilt.

Als Beispiel wird anschließend der \textit{agglomerative-hierarchische Cluster-Algorithmus} genauer vorgestellt.
Sein Vorgehen lässt sich sehr gut anhand sogenannter Dendrogramme oder geschachtelter Cluster-Diagramme darstellen
(siehe Abbildung \ref{fig:grund_agglo_clustering}).

% TODO: Bild selbst erstellen
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{resources/img/grundlagen/agglo_clustering}
    \caption{Agglomeratives Clustering dargestellt als Dendrogramm (links) und geschachteltes Cluster-Diagram (rechts)}
    \label{fig:grund_agglo_clustering}
\end{figure}

Im ersten Schritt des Algorithmus werden alle Datenpunkte als separate Cluster markiert. Diesen Schritt
repräsentieren die Blätter des Dendrogramms.
Anschließend muss ein Distanzmaß und ein Link-Kriterium gewählt werden.
Das am häufigsten verwendete Distanzmaß ist sicherlich der euklidsche Abstand, welcher die Distanz zwischen zwei Punkten
oder Vektoren im $n$-dimensionalen Raum bestimmt. Er ist definiert durch die Formel \ref{eq_dist}.

\begin{ceqn}
\begin{align}
\label{eq_dist}
    dist(p,q) = ||q-p||_2 = \sqrt{\sum_{i=1}^n (q_i-p_i)^2}
\end{align}
\end{ceqn}

Wird als Link-Kriterium beispielsweise \textit{Minimum-Linkage} gewählt, ist dieses definiert als:

\begin{ceqn}
\begin{align}
\label{eq_linkage}
    link(P, Q) = min\{ dist(p,q)\ |\ p \in P, q \in Q\}
\end{align}
\end{ceqn}

Hierbei entsprechen $P$ und $Q$ zwei Clustern, welche die Elemente $p \in P$ und $q \in Q$ enthalten.
Auf Basis des gewählten Link-Kriteriums kann nun eine Distanz-Matrix für die einzelnen Cluster
erstellt werden.
Die zwei Cluster mit minimalem Abstand voneinander werden anschließend zusammengeführt und die
vorherigen Schritte werden wiederholt, bis nur noch ein Cluster (Wurzel des Dendrogramms) beziehungsweise
die gewünschte Clusteranzahl übrig ist. \cite[]{GeorgeSeif2018, tan2007introduction}

Bei den meisten Varianten des agglomerativen Clusterings muss der Nutzer die Anzahl der Zielcluster im
vorraus festlegen, was problematisch ist, da diese meist nicht bekannt ist. Umgangen werden kann dies nur,
indem ein Link-Kriterium gewählt wird, das ab einer bestimmten Distanz zwischen den Clustern diese nichtmehr
fusioniert \cite[]{GeorgeSeif2018}.

Die Zeitkomplexität des agglomerativen Clusterings beträgt bestenfalls $O(n^2log\ n)$, weshalb die Menge der Daten,
welche mit ihm verarbeitet werden können erheblich begrenzt ist \cite[]{tan2007introduction}.

\subsection{Prototyp-Modelle}
\label{sec:grund_prototype_clustering}

Centroid basierte Cluster-Modelle betrachten im Gegensatz zu hierarchischen Modellen nicht die Distanz
zwischen Clustern, sondern die Entfernung von Objekten zu Referenzpunkten, sogenannten \textit{Prototypen}.
Die am häufigsten verwendeten Prototypen sind \textit{Centroids}, welche den Mittelpunkt eines Clusters dargestellen.
\textit{Medoids}, welche auch häufig genutz werden, repräsentieren hingegen den Median eines Clusters.

Ein Beispiel für einen Centroid-Cluster-Algorithmus ist \textit{k-Means}. Dieser ist aufgrund seines Alters,
seiner Einfachheit und der vielen Weiterentwicklungen wohl der bekannteste Cluster-Algorithmus überhaupt.

Das Ziel von k-Mean ist es, für eine n-dimensionale Punktmenge $X = \{ x_1 ... x_n \}$ ein Cluster-Set $C = \{ c_1 ... c_k \}$
zu finden, welches die Summe der quadratischen Abweichung (Gleichung \ref{eq_kmeans1}) zwischen allein Punkten in einem Cluster und deren
Mittelwert $\mu_k$ (Centroids) minimiert.

\begin{ceqn}
\begin{align}
    \label{eq_kmeans1}
    J(c_k) = \sum_{k=1}^K \sum_{x_i \in c_k} || x_i - \mu_k ||^2
\end{align}
\end{ceqn}

Eine Lösung für dieses Problem zu finden, ist NP-Schwer. Aus diesem Grund
ist k-Means ein approximativer Ansatz, welcher nicht garantieren kann, ein globales Minimum zu finden.
Die Funktionsweise des Algorithmus ist in Abbildung \ref{fig:grund_kmeans_clustering} dargestellt.
Die Kreuze entsprechen hierbei den Centroids, welche sich über die Iterationen hinweg verschieben.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{resources/img/grundlagen/k-means}
    \caption[Funktionsweise von k-Means]{Funktionsweise von k-Means \cite[]{tan2007introduction}}
    \label{fig:grund_kmeans_clustering}
\end{figure}

Ausgehend von der Punktmenge $X$ und der gesuchten Cluster-Anzahl $k$,
werden im ersten Schritt $k$ zufällig positionierte Centroids $\mu_k$ definiert.
Anschließend wird für alle Punkte $x_i$ der nächstgelegene Centroid $\mu_j$ gesucht.

\begin{ceqn}
\begin{align}
    \label{eq_kmeans2}
    j = arg\ min(dist(x_i, \mu_j))
\end{align}
\end{ceqn}

$x_i$ wird daraufhin Mitglied in Cluster $C_j$. Als Distanzmaß ($dist$) kann hier wieder der euklidsche Abstand
(Gleichung \ref{eq_dist}) verwendet werden oder aber auch beliebige andere sinnvolle Metriken.
Nachdem alle Punkte $x_i$ einem Cluster zugewiesen wurden, werden die Centroid Positionen neu bestimmt.
Hierzu wird der Durchschnitt aller Punkte eines Clusters berechnet:

\begin{ceqn}
\begin{align}
    \label{eq_kmeans3}
    c_j = \frac{1}{n} \sum_{x_j \in C_j} x_j
\end{align}
\end{ceqn}

Diese zwei Schritte werden mehrfach wiederholt, bis das Ergebnis konvergiert, das heißt die Zuweisungen sich
nurnoch geringfügig ändern. \cite[]{Jain2010}

Der primäre Nachteil des k-Means Algorithmus ist, das auch bei ihm die Anzahl der Zielcluster spezifiziert
werden muss. Desweiteren ist sein Ergebnis aufgrund der zufälligen Initialisierung der Centroids
nicht deterministisch. Vorteil von k-Means ist hingegen, dass seine Zeitkomplexität bei $O(n)$ liegt.

Um die genannten Nachteile, zumindest in Teilen, umgehen zu können, existieren diverse Weiterentwicklungen des k-Mean
Algorithmus. So stammen beispielsweise von \cite[]{Hamerly} und \cite[]{Pelleg} die Algorithmen \textit{g-Means}
beziehungsweise \textit{x-Means}, welche die Clusteranzahl $k$ auf Basis mehrerer k-Means Durchläufe und
statistischer Kennzahlen bestimmen.

\subsection{Distributions-Modelle}
\label{sec:grund_distribution_clustering}

Distributions-Cluster-Modelle basieren auf der Verwendung von statistischen Wahrscheinlichkeitsverteilungen wie
beispielsweise der Gauß-Verteilung. Cluster werden darüber definiert, wie wahrscheinlich es ist, dass Objekte
der selben Verteilung angehören. Problematisch ist die Verwendung dieser Cluster-Methodik, da sie anfällig für
das Problem des \textit{``Overfitting''} ist, wenn die Komplexität der verwendeten Modelle nicht beschränkt wird.
Zudem ist die Annahme, dass vielen realen Datensätzen ein statistisches Verteilungsmodell zugrundeliegt, gefährlich.
Ist diese These jedoch berechtigt, haben die Modelle den Vorteil, dass sie neben der Zuweisung von Objekten zu Clustern
auch Korrelationen zwischen einzelnen Attributen aufzeigen können. \cite[]{AndersDrachen2014}

Nachfolgend wird der bekannteste Vertreter der Distributions-Cluster-Algorithmen vorgestellt:
das \textit{Expectation–maximization} (\acrshort*{em}) Verfahren unter Verwendung sogenannter \textit{Gaussian-Mixture-Models} (\acrshort*{gmm}).
Die Funktionsweise des EM-Algorithmus hat grundsätzlich viel gemein mit der des k-Mean Ansatzes.
Es wird ebenfalls mit einer festen Anzahl zufällig initialisierter Modelle gestartet, welche anschließend über mehrere Iterationen
an die Daten angepasst werden. Im Gegensatz zu k-Means, sind die gewählten Modelle hingegen Gauß-Verteilungen,
welche zwei Parameter besitzen: ihren Mittelwert und die Standardabweichung.
Das Vorgehen des EM-Algorithmus ist nachfolgend, basierend auf \cite[]{GeorgeSeif2018}, beschrieben und in
Abbildung \ref{fig:grund_em_clustering} grafisch dargestellt.

\begin{description}
    \item[1)] Wahl der Clusteranzahl $k$ und Initialisierung der Gauß-Modelle für die entsprechenden Cluster.
    \item[2)] Berechnung der Wahrscheinlichkeit, dass ein Datenpunkt zu einem Cluster gehört. Je näher
              ein Datenpunkt dem Zentrum einer Gauß-Verteilung ist, desto höher die Wahrscheinlichkeit für dessen Zugehörigkeit.
    \item[3)] Basierend auf den Wahrscheinlichkeiten werden die Parameter der Verteilungen neu berechnet.
              Hierzu wird die gewichtete Summe der Datenpunkt-Positionen errechnet. Die Gewichte entsprechen dabei
              den Wahrscheinlichkeiten, dass ein Element zu einem Cluster gehört. Hierdurch werden die Gauß-Modelle automatisch
              den in den Daten enthaltenen Clustern angepasst.
    \item[4)] Wiederholdung der Schritte 2) und 3), bis das Clustering-Ergebnis konvergiert.
\end{description}

\begin{figure}[H]
    \centering
    \subfloat[Iteration 1]{{
        \includegraphics[align=c, width=0.22\linewidth]{resources/img/grundlagen/clustering_EM/EM1}
    }}
    \subfloat[Iteration 2]{{
        \includegraphics[align=c, width=0.22\linewidth]{resources/img/grundlagen/clustering_EM/EM2}
    }}
    \subfloat[Iteration 3]{{
        \includegraphics[align=c, width=0.22\linewidth]{resources/img/grundlagen/clustering_EM/EM3}
    }}
    \subfloat[Iteration 4]{{
        \includegraphics[align=c, width=0.22\linewidth]{resources/img/grundlagen/clustering_EM/EM4}
    }}
    \caption[Darstellung des EM-Cluster-Algorithmus über mehrere Iterationen]{Darstellung des EM-Cluster-Algorithmus über mehrere Iterationen \cite[]{GeorgeSeif2018}}
    \label{fig:grund_em_clustering}
\end{figure}

Ziel des EM-Algorithmus ist es, die Parameter der Gauß-Modelle so zu optimieren, dass diese die Verteilung der Daten bestmöglich beschreiben.
Am Ende des Clusterings besitzt jeder Datenwert die Zugehörigkeits-Wahrscheinlichkeiten für die einzelnen Cluster.
Ein Element wird jenem Cluster zugeordnet, für welches es die höchste Wahrscheinlichkeit besitzt.

\subsection{Dichte-Modelle}
\label{sec:grund_density_clustering}

Dichte basierte Cluster sind, wie oben beschrieben, definiert als Regionen hoher Objektdichte, welche
von Bereichen geringer Dichte umgeben sind. Dichte-Clustering-Modelle suchen nach eben solchen Regionen.
Ein großer Vorteil der Algorithmen dieser Klasse ist, dass sie Cluster beliebiger Formen finden können,
nicht auf die Vorgabe einer Clusteranzahl angewiesen sind und mit Ausreißern umgehen können.

Als Vertreter der Dichte-basierten Ansätze wird nachfolgend der \textit{\acrshort*{dbscan}} Algorithmus
(\textit{Density-Based Spatial Clustering of Applications with Noise}), wie in \cite[]{Gao2012} beschrieben, vorgestellt.
Er verwendet als Maß für die Dichte einer Region die sogenannte \textit{$\epsilon$ -Nachbarschaft} (\textit{Eps}).
Diese selektiert für ein Objekt $p$ alle Objekte, welche innerhalb des Radius $\epsilon$ um dieses liegen:

\begin{ceqn}
\begin{align}
    \label{eq_dbscan_1}
    N_{\epsilon}(p) = \{ q\ |\ dist(p,q) \leq \epsilon \}
\end{align}
\end{ceqn}

Eine $\epsilon$ -Nachbarschaft besitzt eine hohe Dichte, wenn in ihr mindestens $MinPts$ Objekte liegen.

Basierend auf der Definition von \textit{Eps}, werden die in einem Datensatz vorhandenen Elemente in
drei Klassen unterteilt. Sie sind entweder \textit{Kern-}, \textit{Rand-} oder \textit{Ausreißer-} Objekte.
Ein Kernobjekt hat mindestens $MinPts$ andere Punkte in \textit{Eps}.
Randobjekte besitzen weniger als $MinPts$ in \textit{Eps}, liegen aber in der Nachbarschaft eines Kernobjektes.
Ausreißerobjekte sind weder Kern- noch Randobjekte.

\begin{figure}[H]
    \centering
    \subfloat[]{{
        \includegraphics[align=c, width=0.3\linewidth]{resources/img/grundlagen/clustering_dbscan/dbscan1}
    }}
    \subfloat[]{{
        \includegraphics[align=c, width=0.3\linewidth]{resources/img/grundlagen/clustering_dbscan/dbscan2}
    }}
    \subfloat[]{{
        \includegraphics[align=c, width=0.3\linewidth]{resources/img/grundlagen/clustering_dbscan/dbscan3}
    }}
    \caption[Schritte des DBSCAN Algorithmus]{Schritte des DBSCAN Algorithmus, a) Rohdaten, b) Klassifizierung in Kern- (grün), Rand- (blau) und Ausreißer- (rot) Punkte, c) Cluster Ergebnis \cite[]{Gao2012}}
    \label{fig:grund_dbscan_clustering}
\end{figure}

Auf Basis der drei Objektklassen, lässt sich das Prinzip der dichte-basierten \textit{Erreichbarkeit} definieren.
Ein Objekt $q$ ist von $p$ \textit{direkt} erreichbar, wenn $p$ ein Kernobjekt ist und $q$ in dessen \textit{Eps} liegt.
In Abbildung \ref{fig:grund_dbscan_reachability} gilt dies beispielsweise für $p$ und $p_2$.
Zwei Elemente sind \textit{indirekt} erreichbar, wenn sie über eine Reihe von Zwischenschritten (direkte Relationen)
verbunden sind (transitiv). Dies ist in Abbildung \ref{fig:grund_dbscan_reachability} für $q$ und $p$ der Fall.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.32\linewidth]{resources/img/grundlagen/clustering_dbscan/reachability}
    \caption[Erreichbarkeit in DBSCAN]{Erreichbarkeit in DBSCAN \cite[]{Gao2012}}
    \label{fig:grund_dbscan_reachability}
\end{figure}

Der DBSCAN Algorithmus lässt sich, basierend auf den obigen Definitionen, informell wie folgt beschreiben:

\begin{description}
    \item[1)] Unterteilung der Objekte in die drei Objektklassen. (Abb. \ref{fig:grund_dbscan_clustering} b))
    \item[2)] Aussortierung der Ausreißer-Objekte.
    \item[3)] Wahl eines nicht zugewiesenen Kernobjektes.
    \item[4)] Erstellung eines neuen Clusters für das Kernobjekt und alle von ihm ausgehend direkt oder indirekt erreichbaren Objekte.
    \item[5)] Wiederholdung der Schritte 3) und 4), bis alle Kern- und Randobjekte einem Cluster zugewiesen sind. (Abb. \ref{fig:grund_dbscan_clustering} c))
\end{description}

DBSCAN besitzt die oben beschriebenen Vorteile Dichte-basierter Cluster-Algorithmen. Dank einer Zeitkomplexität
von $O(n\ log\ n)$ kann er außerdem auch auf große Datensätze angewendet werden.
Nachteil des Ansatzes ist hingegen, dass er schlecht mit Clustern umgehen kann, welche unterschiedliche Dichten besitzen.

\section{Distanzmaße zum Vergleich von Fahrzeugtrajektorien}
\label{sec:distance_measures}

Bei der Clusteranalyse ist neben der Wahl des passenden Cluster-Algorithmus insbesondere
die Entscheidung, welches Distanzmaß verwendet wird, ausschlaggebend.
Im obigen Abschnitt wurden bereits die euklidsche Distanz (Gleichung \ref{eq_dist}) als ein mögliches Distanzmaß
definiert. Dieses kann jedoch nur zur Bestimmung der Distanz zwischen $n$-dimensionalen Punkten im euklidschen Raum verwendet
werden. Dies gilt ebenso für andere einfache Maße wie die Manhatten-Distanz oder die Pearson-Distanz.

Um Fahrzeugtrajektorien korrekt gruppieren zu können, ist ein Distanzmaß notwendig, welches je nach Anforderungen
die unterschiedlichen Aspekte der Trajektorien vergleicht. Häufig werden die Eigenschaften Lage, Form und Länge
hierzu herangezogen. In der Literatur werden diverse Maße zum Vergleich von Trajektorien vorgestellt. Diese besitzen
alle unterschiedliche Eigenschaften, Vor- und Nachteile.

% TODO: Unterschied Metric und Maß

Nachfolgend werden exemplarisch drei Distanzmaße vorgestellt, anhand welcher ersichtlich ist, welche Abwägungen
bei der Wahl des Maßes gemacht werden müssen.
In allen drei Fällen werden die Trajektorien als Reihen 2-dimensionaler Punkte mit Länge $n$ interpretiert: $t_i = \{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\}$.
Der $n$-te Punkt einer Trajektorie ist gegeben über $t_i(n)$ und deren Punkt-Länge über $len(t_i)$.
Die Menge der zu vergleichenden Trajektorien ist $T = \{t_1, t_2, ..., t_m\}$.
Abbildung \ref{fig:grund_trajectories} zeigt eine Auswahl möglicher Trajektorien.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{resources/img/grundlagen/trajectories}
\caption{Trajektorien im 2-dimensionalen Raum}
\label{fig:grund_trajectories}
\end{figure}

\subsection{HU-Distanz}
\label{sec:hu_distance}

Die HU-Distanz wurde erstmals in der Arbeit \textit{``Similarity based vehicle trajectory clustering and anomaly detection''}
von \cite[]{Hu2005} verwendet. Es ist ein sehr einfaches Distanzmaß, welches auf der mittleren euklidschen Distanz
zwischen zwei Trajektorien basiert. Berechnet wird die HU-Distanz für zwei Trajektorien $t_1$ und $t_2$ wie folgt:

\begin{ceqn}
\begin{align}
\label{eq_hu_distance1}
    D_{HU}(t_1, t_2) &= \frac{1}{N} \sum_{n = 1}^N dist(t_1(n), t_2(n)) \\
\label{eq_hu_distance2}
    wobei\ N &= min(len(t_1), len(t_2))
\end{align}
\end{ceqn}

Aus dieser Formel lassen sich sowohl die Vor- als auch Nachteile der HU-Distanz ableiten. Der klare Vorteile der
HU-Distanz ist deren Einfachheit und die Effizienz von $O(n)$.
Nachteil ist hingegen, dass das Distanzmaß nur gut funktioniert, wenn die Trajektorien bestimmte
Kriterien erfüllen. So sollten Trajektorien, welche einem Cluster angehören, auch immer möglichst auf selber Höhe beginnen,
damit deren mittlerer Abstand nicht, aufgrund einer Verschiebung, erhöht wird.
Außerdem ist es notwendig, die Abstände zwischen den Punkten der Trajektorien auf die selbe Länge zu bringen,
damit beim paarweisen Vergleich immer Elemente verglichen werden, welche gleichweit vom Start der Spuren entfernt sind.
Diese Eigenschaften der Trajektorien müssen über einen Vorverarbeitungsschritt geschaffen werden.
Problematisch bei der Verwendung der HU-Distanz ist außerdem, dass beim Vergleich zweier Trajektorien immer nur
die ersten $N$ Punkte (s. Gleichung \ref{eq_hu_distance2}) betrachtet werden. Die kann dazu führen, dass zwei
Trajektorien, welche zu Beginn fast identisch sind und später auseinanderlaufen, trotzdem einen hohen Ähnlichkeitswert besitzen
(siehe $t_5$ und $t_6$ in Abbildung \ref{fig:grund_trajectories}).

Die HU-Distanz kann aufgrund der genannten Einschränken nur in speziellen Fällen oder unter Verwendung eines
Vorverarbeitungsschrittes angewandt werden. Sie liefert ansonsten schlechte Clustering Ergebnisse.

\subsection{Hausdorff-Distanz}
\label{sec:hausdorff_distance}

Die Hausdorff-Distanz ist ein komplexeres Maß zur Bestimmung der Ähnlichkeit zwischen zwei Trajektorien.
Sie misst grundsätzlich den Abstand zwischen zwei nicht-leeren, ungeordneten Teilmengen $A$ und $B$ und ist für
Trajektorien definiert über die Gleichungen \cite[]{Atev2010}:

\begin{ceqn}
\begin{align}
\label{eq_hausdorff1}
    D_{HD}(t_1, t_2) &= max(h(t_1, t_2), h(t_2, t_1)) \\
\label{eq_hausdorff2}
    h(t_1, t_2) &= \underset{i\ \in\ t_1}{max}\ \underset{j\ \in\ t_2}{min}\ dist(i, j)
\end{align}
\end{ceqn}

$h(t_1, t_2)$ wird als gerichtete Hausdorff-Distanz \textit{von} $t_1$ \textit{nach} $t_2$ bezeichnet.
Sie findet die maximale Distanz einer Trajektorie zum nächsten Punkt der anderen Trajektorie \cite[]{Huttenlocher}.
Da $h$ gerichtet ist, gilt $h(t_1, t_2) \neq h(t_2, t_1)$. Aus diesem Grund wird die Hausdorff-Distanz
\textit{zwischen} zwei Trajektorien mittels $D_{HD}$ bestimmt. $dist$ kann ein beliebiges Maß für die Distanz zweier
Punkte sein, wie beispielsweise die euklidsche Distanz.
Grundsätzlich lässt sich über die Hausdorff-Distanz die Form zweier Trajektorien vergleichen. Diese sind ähnlich,
wenn jeder Punkt einer Trajektorie einen nahegelegenen Punkt in der Vergleichsbahn besitzt.

Vorteil der Hausdorff-Distanz im Vergleich zur HU-Distanz ist, dass diese immer vollständige Trajektorien vergleicht
und nicht nur Teile. Außerdem ist bei ihrer Verwendung keine Vorverarbeitung in Form von Resampling et cetera notwendig.
Problematisch ist das Distanzmaß hingegen, da es mit ungeordneten Sets arbeitet und somit im Fall von Trajektorien, deren
Orientierung nicht beachtet. Zwei parallel aber in entgegengesetzte Richtungen laufende Trajektorien, wie beispielsweise
die Trajektorien $t2$ und $t3$ in Abbildung \ref{fig:grund_trajectories}, würden nach Hausdorff daher eine hohe Ähnlichkeit besitzen.
Zudem kann das Distanzmaß schlecht mit Ausreißern umgehen, da bereits ein einzelner dieser Punkte, bei ansonsten identischen
Trajektorien, zu einer beliebig kleinen Ähnlichkeit führen kann.
Von Nachteil ist auch, dass die Zeitkomplexität der Hausdorff-Distanz bei $O(n\ m)$ liegt.

\subsection{Longest-Common-Subsequence}
\label{sec:lcss_distance}

Das \textit{Longest-Common-Subsequence} (\acrshort*{lcss}) Distanzmaß basiert auf dem allgemeinen Problem der Findung
einer längsten gemeinsamen Subsequenz zwischen zwei Sequenzen. Da Trajektorien, nach obiger Definition, lediglich Punktfolgen sind,
lässt sich das Verfahren sehr gut auf diese anwenden. Aufgrund einiger kleiner Erweiterungen des Basis-Algorithmus, besitzt
das LCSS Distanzmaß einige besondere Eigenschaften. Der LCSS Algorithmus für Trajektorien ist grundsätzlich
wie folgt definiert \cite[]{Vlachos2002}:

\begin{ceqn}
\begin{align}
\label{eq_lcss}
    LCSS_{\epsilon, \delta}(t_1, t_2) =
    \begin{cases}
        0 & \text{if } t_1 \text{ or } t_2 \in \emptyset \\
        1 + LCSS_{\epsilon, \delta}(t_1', t_2') & \text{if } dist(t_1(n), t_2(m)) < \epsilon \\
        & \land\ |n - m| \leq \delta \\
        max(LCSS_{\epsilon, \delta}(t_1', t_2), LCSS_{\epsilon, \delta}(t_1, t_2')) & \text{otherwise}
    \end{cases}
\end{align}
\end{ceqn}

Hierbei gilt $t_1' = \{ t_1(0),\ ...,\ t_1(n-1)\}$. Die Parameter $\epsilon$ und $\delta$ bestimmen das
Vergleichs-Verhalten des Algorithmus. Über $\epsilon$ wird definiert, wieweit zwei Punkte maximal voneinander entfernt liegen
können, um immer noch als ``übereinstimmend'' zu gelten. $\delta$ bestimmt hingegen, wieweit man in beide zeitliche Richtungen
sucht, um einen übereinstimmenden Punkt zu finden.
% Abbildung XXX veranschaulicht die Bedeutung von $\epsilon$ und $\delta$. TODO: Evtl. Bild noch einfügen
Da die obige LCSS Funktion nur ein diskretes Zählmaß definiert, ist das eigentliche LCSS-Distanz üblicherweise
gegeben als \cite[]{Vlachos2002}:

\begin{ceqn}
\begin{align}
\label{eq_lcss_distance}
    D_{LCSS}(\delta, \epsilon, t_1, t_2) = 1 - \frac{LCSS_{\delta, \epsilon}(t_1, t_2)}{min(len(t_1), len(t_2))}
\end{align}
\end{ceqn}

% TODO: Bild (LCSS Parametererläuterung) hinzufügen und referenzieren (Vlachos et al.)

Vorteile der LCSS Ähnlichkeitdefinition sind, dass sie mit kompletten Trajektorien arbeitet und robust
gegenüber Ausreißern ist, da nicht für alle Punkte Übereinstimmungen in den Trajektorien gefunden werden müssen.
Über $\epsilon$ und $\delta$ kann die ``Strenge'' des Algorithmus geregelt werden.
Zudem berücksichtigt das LCSS Maß die Orientierung der Trajektorien, solange $\delta$ nicht zu hoch gewählt wird.
Die rekursive Definition des LCSS Algorithmus aus Gleichung \ref{eq_lcss} lässt sich mittels dynamischer Programmierung
mit Zeitkomplexität $O(n\ m)$ berechnen.

\subsubsection{Übersicht Distanzmaße}

Anhand der drei ausgewählten und oben exemplarisch beschriebenen Distanzmaße, ist bereits ersichtlich,
dass die Wahl eines passenden Maßes nicht trivial ist. Es muss die Qualität und Form der Daten berücksichtigt werden
und abgewogen werden, in wieweit es möglich beziehungsweise gewünscht ist, die Daten vorzuverarbeiten.
Das primäre Auswahlkriterium ist allerdings natürlich die situationsabhängige Definition von ``Distanz'':
Sind sich Trajektorien ähnlich, wenn sie lediglich die selbe Form haben und ansonsten irgendwo im Raum liegen? Sind sie
sich ähnlich, wenn sie die selbe Form haben und im Raum nahe beieinander liegen? Ist ihre Orientierung relevant?
Dies sind wichtige Fragen, welche vor der Wahl eines Distanzmaßes geklärt werden müssen.
Da die Maße als Distanzfunktionen bei der Clusteranalyse verwendet werden, ist ihr Verhalten ausschlaggebend
für den Erfolg der Gruppierung von Trajektorien.

Wichtige Eigenschaften einiger in der Literatur häufig verwendeten Vergleichsmaße, inklusive der drei oben beschriebenen,
sind nachfolgend nochmals in tabellarischer Form festgehalten.

% TODO: Tablle überarbeiten
\begin{table}[H]
    \caption{Eigenschaften verschiedener Distanzmaße}
    \label{tab:parallelen}
    \centering
    \begin{tabular}{l|ccc}
        \toprule
        \textbf{Distanzmaß} & \textbf{gerichtet} & \textbf{PreProc. nötig} & \textbf{Ausreißer-resistent} \\
        \midrule \addlinespace
        HU \cite[]{Hu2005} & \cmark & \cmark & \cmark \\
        \addlinespace
        \acrshort{pca} \cite[]{Bashir2003} & \cmark & \cmark & \cmark \\
        \addlinespace
        \acrshort*{dtw} \cite[]{Keogh2000} & \cmark & \xmark & \xmark \\
        \addlinespace
        \acrshort*{hd} \cite[]{Chen2011} & \xmark & \xmark & \xmark \\
        \addlinespace
        mod. HD \cite[]{Atev2006} & \cmark & \xmark & \cmark \\
        \addlinespace
        PF \cite[]{Piciarelli2006} & \cmark & \xmark & \xmark \\
        \addlinespace
        LCSS \cite[]{Vlachos2002} & \cmark & \xmark & \cmark \\
        \addlinespace
        \bottomrule
    \end{tabular}
\end{table}
